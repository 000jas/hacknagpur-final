# üõ°Ô∏è CivicGuard

**AI-Powered Harassment Detection System**

Transform CCTV cameras into proactive safety systems using pose-based behavioral analysis.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Accuracy](https://img.shields.io/badge/accuracy-85%25-brightgreen.svg)]()

> **Privacy-First**: No facial recognition. Only behavioral pose analysis.

---

## üìã Table of Contents

- [What It Does](#-what-it-does)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [How It Works](#-how-it-works)
- [Usage](#-usage)
- [API Integration](#-api-integration)
- [Model Training](#-model-training)
- [Project Structure](#-project-structure)
- [Performance](#-performance)
- [Troubleshooting](#-troubleshooting)

---

## üéØ What It Does

CivicGuard analyzes live video feeds to detect harassment and suspicious behavior patterns **before they escalate**.

### Detection Capabilities:

- ‚úÖ **Personal Space Invasion** - Detects when someone gets too close
- ‚úÖ **Following Behavior** - Identifies persistent trailing patterns
- ‚úÖ **Loitering** - Flags suspicious lingering near targets
- ‚úÖ **Approach Patterns** - Analyzes approach speed and consistency
- ‚úÖ **Evasion Detection** - Recognizes when someone tries to flee

### Real-World Applications:

- üè¢ Corporate offices and workplaces
- üè´ Educational institutions
- üè• Healthcare facilities
- üöá Public transportation hubs
- üè™ Retail stores and malls

**Key Advantage**: Detects behavioral patterns over time, not just single moments.

---

## üöÄ Quick Start

### Prerequisites

- Python 3.8 or higher
- Webcam or IP camera
- 4GB RAM minimum (8GB recommended)
- (Optional) NVIDIA GPU for faster processing

### 1-Minute Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/CivicGuard.git
cd CivicGuard

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run detection!
python src/harassment_detection.py
```

**That's it!** Point your camera and the system will start detecting.

---

## üì¶ Installation

### Step 1: Clone Repository

```bash
git clone https://github.com/yourusername/CivicGuard.git
cd CivicGuard
```

### Step 2: Create Virtual Environment (Recommended)

```bash
# Create virtual environment
python -m venv venv

# Activate it
# On macOS/Linux:
source venv/bin/activate

# On Windows:
venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

**Dependencies include:**

- `ultralytics` - YOLOv8 for pose detection
- `opencv-python` - Video processing
- `xgboost` - Machine learning classifier
- `scikit-learn` - Feature scaling and metrics
- `numpy` - Numerical operations
- `flask` - REST API server (optional)

### Step 4: Download Pre-trained Model

The YOLO pose model will download automatically on first run.

**Manual download (if needed):**

```bash
# Create yolo directory
mkdir -p yolo

# Download YOLOv8n-pose
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt -O yolo/yolov8n-pose.pt
```

### Verify Installation

```bash
python -c "import cv2, ultralytics, xgboost; print('‚úÖ All dependencies installed!')"
```

---

## üîß How It Works

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Camera Feed ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  YOLO Pose Detection       ‚îÇ
‚îÇ  (17 keypoints per person) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Track People Over Time    ‚îÇ
‚îÇ  (10-frame sequences)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Extract 60 Features       ‚îÇ
‚îÇ  ‚Ä¢ 40 Temporal             ‚îÇ
‚îÇ  ‚Ä¢ 15 Interaction          ‚îÇ
‚îÇ  ‚Ä¢ 5 Harassment Indicators ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  XGBoost Classifier        ‚îÇ
‚îÇ  (85% accuracy)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Harassment Alert + Score  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Detailed Pipeline

#### 1Ô∏è‚É£ **Pose Detection (YOLOv8n-pose)**

- Detects people in every frame
- Extracts 17 keypoints per person:
  - Head, shoulders, elbows, wrists
  - Hips, knees, ankles
- Confidence scores for each keypoint
- **Speed**: ~30 FPS on CPU, ~100+ FPS on GPU

#### 2Ô∏è‚É£ **Temporal Tracking**

- Tracks each person across 10 consecutive frames
- Builds movement trajectories
- Calculates velocities and accelerations
- Maintains person identity throughout video
- **Window**: 10 frames (~0.33 seconds at 30 FPS)

#### 3Ô∏è‚É£ **Feature Extraction (60 Features)**

**Temporal Features (40):**

- Movement speed and direction
- Acceleration patterns
- Path trajectory analysis
- Position changes over time
- Body orientation dynamics

**Interaction Features (15):**

- Interpersonal distance
- Facing direction alignment
- Personal space zones (intimate, personal, social)
- Proximity duration
- Mutual gaze indicators

**Harassment Indicators (5):**

- `invasion_score` - Personal space violations
- `following_score` - Persistent trailing
- `loitering_score` - Suspicious lingering
- `approach_score` - Aggressive approach patterns
- `evasion_score` - Target fleeing behavior

#### 4Ô∏è‚É£ **Classification (XGBoost)**

- **Model**: XGBoost with 500 estimators
- **Training**: UCF Crime Dataset (Abuse, Assault, Fighting vs Normal)
- **Features**: 60 engineered behavioral features
- **Output**: Harassment probability (0-100%)
- **Threshold**: 70% default (configurable)

#### 5Ô∏è‚É£ **Alert Generation**

- **Standalone Mode** (`harassment_detection.py`): Real-time alerts with full visualization
- **API Mode** (`api_server.py`): Same visualization + aggregated JSON alerts every 20 seconds
- **Output**: JSON with confidence, threat level, session details

---

## üéÆ Usage

### Basic Detection (Webcam)

```bash
python src/harassment_detection.py
```

**Controls:**

- Press `q` to quit
- Real-time visualization with:
  - Person IDs
  - Pose skeletons
  - Confidence scores
  - Alert levels

### REST API Server (For Frontend Integration)

```bash
python src/api_server.py
```

**Features:**

- Built with **FastAPI** (async, modern, fast)
- Uses the same visualization as `harassment_detection.py` (keypoint skeletons, interaction lines)
- Shows live camera feed with all the nice pose drawings
- Aggregates alerts every 20 seconds (configurable) for frontend dashboards
- Prevents frontend spam while maintaining real-time monitoring
- **Auto-generated API docs** at `/docs` (Swagger) and `/redoc`

**API runs on:** `http://localhost:5001`

**API Documentation:**

- Swagger UI: http://localhost:5001/docs
- ReDoc: http://localhost:5001/redoc

**Output Example (API Response):**

```json
{
  "status": "THREAT_DETECTED",
  "threat_level": "HIGH",
  "confidence": 0.87,
  "detections": 15,
  "timestamp": "2026-02-01T14:30:45"
}
```

**Quick test:**

```bash
# Start detection
curl -X POST http://localhost:5001/api/start \
  -H "Content-Type: application/json" \
  -d '{"alert_interval": 20, "confidence_threshold": 0.70}'

# Get latest alert
curl http://localhost:5001/api/latest-alert

# Get statistics
curl http://localhost:5001/api/stats
```

See [API_DOCUMENTATION.md](API_DOCUMENTATION.md) for full API reference.

---

## üåê API Integration

### For Frontend Developers

**Simple polling example (JavaScript/React):**

```javascript
// Start detection
await fetch("http://localhost:5001/api/start", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({ alert_interval: 20, confidence_threshold: 0.7 }),
});

// Poll every 5 seconds for alerts
setInterval(async () => {
  const res = await fetch("http://localhost:5001/api/latest-alert");
  const alert = await res.json();

  if (alert.status === "THREAT_DETECTED") {
    console.log(`‚ö†Ô∏è  ${alert.threat_level}: ${alert.confidence}%`);
    updateDashboard(alert);
  }
}, 5000);
```

**Threat Levels:**

- `CRITICAL`: ‚â• 90% - Immediate response needed
- `HIGH`: 80-89% - Alert security team
- `MEDIUM`: 70-79% - Monitor closely
- `LOW`: < 70% - Log for review

---

## üéì Model Training

### Using Pre-trained Model (Recommended)

The repository includes a pre-trained model with **85% accuracy**.

**Location:** `models/harassment_detector_v2.pkl`

### Training Your Own Model

**Step 1: Prepare Dataset**

```bash
# Organize videos into categories
data/frames/train/
‚îú‚îÄ‚îÄ Abuse/          # Harassment examples
‚îú‚îÄ‚îÄ Assault/        # Aggressive behavior
‚îú‚îÄ‚îÄ Fighting/       # Physical confrontation
‚îî‚îÄ‚îÄ NormalVideos/   # Normal interactions
```

**Step 2: Extract Sequences**

```bash
python src/prepare_harassment_sequences.py
```

This creates:

- Temporal sequences (10-frame windows)
- 60 features per sequence
- Balanced dataset with class weights

**Step 3: Train Model**

```bash
python src/train_harassment_model.py
```

**Output:**

```
Training complete!
Accuracy: 85.03%
Harassment Detection Rate: 93.92%
Models saved to:
  - models/harassment_detector_v2.pkl
  - models/harassment_scaler_v2.pkl
```

**Training Data:**

- Dataset: UCF Crime Dataset
- Sequences: 831 temporal sequences
- Classes: Normal (738) vs Abnormal (93)
- Features: 60 behavioral indicators
- Model: XGBoost (500 estimators, max_depth=12)

---

## üìÅ Project Structure

```
CivicGuard/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ harassment_detection.py       # ‚≠ê Main detection (standalone with visualization)
‚îÇ   ‚îú‚îÄ‚îÄ api_server.py                # üåê REST API (same visualization + alert aggregation)
‚îÇ   ‚îú‚îÄ‚îÄ train_harassment_model.py    # üéì Model training
‚îÇ   ‚îú‚îÄ‚îÄ prepare_harassment_sequences.py  # üìä Dataset preparation
‚îÇ   ‚îú‚îÄ‚îÄ interaction_features.py      # üîß Feature extraction
‚îÇ   ‚îú‚îÄ‚îÄ detect_pose.py               # üéØ YOLO pose utilities
‚îÇ   ‚îî‚îÄ‚îÄ config.py                    # ‚öôÔ∏è  Configuration
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ harassment_detector.pkl      # üß† Trained model (85% acc)
‚îÇ   ‚îî‚îÄ‚îÄ sequence_scaler.pkl          # üìè Feature scaler
‚îÇ
‚îú‚îÄ‚îÄ yolo/
‚îÇ   ‚îî‚îÄ‚îÄ yolov8n-pose.pt             # üë§ YOLO pose model
‚îÇ
‚îú‚îÄ‚îÄ data/                            # üìÇ UCF Crime Dataset
‚îÇ   ‚îî‚îÄ‚îÄ frames/train/...
‚îÇ
‚îú‚îÄ‚îÄ alerts/                          # üìã Saved JSON alerts
‚îÇ
‚îú‚îÄ‚îÄ README.md                        # üìñ This file
‚îú‚îÄ‚îÄ API_DOCUMENTATION.md             # üì° API reference
‚îú‚îÄ‚îÄ requirements.txt                 # üì¶ Dependencies
‚îî‚îÄ‚îÄ .env                            # üîê API keys (optional)
```

---

## üìä Performance

### Model Metrics

| Metric                        | Value         |
| ----------------------------- | ------------- |
| **Overall Accuracy**          | 85.03%        |
| **Harassment Detection Rate** | 93.92%        |
| **False Alarm Rate**          | 6.08%         |
| **AUC-ROC Score**             | 0.7486        |
| **Processing Speed**          | ~30 FPS (CPU) |

### Top Predictive Features

1. **invasion_score** (7.04%) - Personal space violations
2. **P2_trajectory_x_mean** (4.60%) - Following patterns
3. **max_distance** (4.53%) - Proximity tracking
4. **loitering_score** (3.01%) - Suspicious lingering
5. **approach_speed** (2.88%) - Aggressive movement

### System Requirements

**Minimum:**

- CPU: Intel i5 or equivalent
- RAM: 4GB
- Python: 3.8+
- Camera: 720p

**Recommended:**

- CPU: Intel i7/Ryzen 7 or better
- RAM: 8GB+
- GPU: NVIDIA GTX 1060 or better
- Camera: 1080p+

### Performance Tips

```bash
# Use GPU acceleration (if available)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Reduce sequence length for faster processing
# Edit src/config.py:
SEQUENCE_LENGTH = 5  # Faster but less accurate

# Lower resolution for speed
# In code: resize frames before processing
```

---

## üõ†Ô∏è Troubleshooting

### Common Issues

**1. Camera not detected**

```bash
# Test camera
python -c "import cv2; cap = cv2.VideoCapture(0); print('Camera OK' if cap.isOpened() else 'Camera Error')"

# Try different camera indices
python src/harassment_detection.py  # Uses camera 0
# or manually change in code: cv2.VideoCapture(1)
```

**2. Models not found**

```bash
# Verify models exist
ls models/harassment_detector_v2.pkl
ls models/harassment_scaler_v2.pkl

# If missing, retrain:
python src/train_harassment_model.py
```

**3. Low FPS / Slow processing**

```bash
# Install GPU support
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Reduce frame resolution
# Edit detection script, add:
# frame = cv2.resize(frame, (640, 480))
```

**4. Too many false alarms**

```bash
# Increase confidence threshold
python src/production_detection.py --threshold 0.85
```

**5. Missing detections**

```bash
# Decrease confidence threshold
python src/production_detection.py --threshold 0.60

# Ensure good lighting
# Check camera angle (front view works best)
```

### Getting Help

1. Check error message carefully
2. Verify all dependencies: `pip list`
3. Ensure Python 3.8+: `python --version`
4. Check camera permissions
5. Review logs in console
6. Open an issue on GitHub with:
   - Error message
   - Python version
   - OS and hardware
   - Steps to reproduce

---

## üîí Privacy & Ethics

### Privacy Commitments

‚úÖ **No Facial Recognition** - System only analyzes body poses  
‚úÖ **No Personal Identification** - Tracks behavior, not identity  
‚úÖ **No Data Retention** - Processes in real-time, no storage  
‚úÖ **Transparent Alerts** - Shows confidence scores and reasoning  
‚úÖ **Human Oversight** - Designed to assist, not replace, security personnel

### Ethical Use Guidelines

**DO:**

- Use for safety and security purposes
- Inform people about monitoring
- Combine with human security staff
- Review and validate alerts
- Respect privacy laws and regulations

**DON'T:**

- Use for surveillance without consent
- Rely solely on automated decisions
- Use in private spaces (bathrooms, changing rooms)
- Store video without proper consent
- Use for discrimination or profiling

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

**For educational and research purposes.**

---

## ü§ù Contributing

Contributions welcome! Areas for improvement:

- [ ] Additional behavioral patterns
- [ ] Multi-camera tracking
- [ ] Enhanced temporal analysis
- [ ] Mobile app integration
- [ ] Cloud deployment guides
- [ ] Additional dataset support

**To contribute:**

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## üìß Support & Contact

- **Issues**: [GitHub Issues](https://github.com/yourusername/CivicGuard/issues)
- **Documentation**: [API Docs](API_DOCUMENTATION.md)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/CivicGuard/discussions)

---

## üôè Acknowledgments

- **Dataset**: UCF Crime Dataset
- **Pose Detection**: Ultralytics YOLOv8
- **ML Framework**: XGBoost
- **Inspiration**: Creating safer communities through AI

---

## üìà Roadmap

- [x] Real-time pose-based detection
- [x] Temporal sequence analysis
- [x] REST API for integration
- [x] Production-ready deployment
- [ ] Multi-camera support
- [ ] Cloud deployment
- [ ] Mobile app
- [ ] Alert notifications (SMS/Email)
- [ ] Dashboard UI
- [ ] Advanced analytics

---

**Built with ‚ù§Ô∏è for safer communities**

_Making the world safer, one frame at a time._ üõ°Ô∏è

# System ready!

````

### 2. Run Detection

```bash
# Live webcam detection
python src/harassment_detection.py
````

**That's it!** The system will:

- ‚úÖ Detect people using YOLO pose estimation
- ‚úÖ Track movement patterns over 10-frame sequences
- ‚úÖ Alert when harassment patterns detected
- ‚úÖ Show confidence scores and person IDs

---

## üìä Performance

- **85% Overall Accuracy**
- **60 Behavioral Features** (temporal + interaction)
- **Trained on UCF Crime Dataset** (Abuse, Assault, Fighting vs Normal)
- **Real-time Processing** (~30 FPS)

---

## üìÅ Project Structure

```
CivicGuard/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ harassment_detection.py      # Main detection system ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ train_harassment_model.py    # Model training
‚îÇ   ‚îú‚îÄ‚îÄ prepare_harassment_sequences.py  # Dataset prep
‚îÇ   ‚îú‚îÄ‚îÄ interaction_features.py      # Feature extraction
‚îÇ   ‚îî‚îÄ‚îÄ config.py                    # Settings
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ harassment_detector_v2.pkl   # Trained model (85% acc)
‚îÇ   ‚îî‚îÄ‚îÄ harassment_scaler_v2.pkl     # Feature scaler
‚îú‚îÄ‚îÄ data/                            # UCF Crime Dataset
‚îî‚îÄ‚îÄ yolo/
    ‚îî‚îÄ‚îÄ yolov8n-pose.pt             # YOLO pose model
```

---

## üîß How It Works

### Detection Pipeline

```
Camera Feed
    ‚Üì
YOLO Pose Detection (17 keypoints/person)
    ‚Üì
10-Frame Temporal Sequences
    ‚Üì
60 Feature Extraction
    ‚îú‚îÄ 40 Temporal Features (speed, trajectory, direction)
    ‚îú‚îÄ 15 Interaction Features (distance, facing, proximity)
    ‚îî‚îÄ 5 Harassment Indicators (following, loitering, invasion)
    ‚Üì
XGBoost Classifier (500 estimators)
    ‚Üì
Harassment Score + Alert
```

### Key Features

**Temporal Analysis:**

- Movement trajectories over time
- Speed and acceleration patterns
- Direction changes and path analysis

**Interaction Analysis:**

- Interpersonal distance
- Facing direction alignment
- Personal space invasion
- Proximity zones

**Harassment Indicators:**

- Following behavior detection
- Loitering near target
- Approach consistency
- Evasion attempts

---

## üéì Training Your Own Model

### 1. Prepare Dataset

```bash
# Organize videos into categories
data/frames/train/
‚îú‚îÄ‚îÄ Abuse/
‚îú‚îÄ‚îÄ Assault/
‚îú‚îÄ‚îÄ Fighting/
‚îî‚îÄ‚îÄ NormalVideos/
```

### 2. Extract Sequences

```bash
python src/prepare_harassment_sequences.py
```

### 3. Train Model

```bash
python src/train_harassment_model.py
```

**Output:**

- `models/harassment_detector_v2.pkl` (trained model)
- `models/harassment_scaler_v2.pkl` (feature scaler)
- Performance metrics and feature importance

---

## üéÆ Usage Examples

### Basic Detection

```bash
python src/harassment_detection.py
```

### Custom Configuration

Edit `src/config.py`:

```python
SEQUENCE_LENGTH = 10  # Frames per sequence
FPS = 5              # Processing frame rate
RISK_THRESHOLD = 0.8  # Alert threshold
```

---

## üìà Model Details

### Architecture

- **Pose Detection**: YOLOv8n-pose (17 keypoints)
- **Classifier**: XGBoost (500 estimators)
- **Features**: 60 temporal + interaction features
- **Window**: 10-frame sequences with stride 5

### Training Data

- **Dataset**: UCF Crime Dataset
- **Categories**: Abuse, Assault, Fighting, NormalVideos
- **Sequences**: 831 temporal sequences
- **Balance**: Weighted class sampling (1:7.94)

### Top Features

1. **invasion_score** (7.04%) - Personal space violations
2. **P2_trajectory_x_mean** (4.60%) - Following patterns
3. **max_distance** (4.53%) - Proximity tracking
4. **loitering_score** (3.01%) - Suspicious lingering
5. **approach_speed** (2.88%) - Aggressive approach

---

## üîí Privacy & Ethics

- ‚úÖ **No Facial Recognition** - Only pose analysis
- ‚úÖ **No Personal Identification** - Tracks behavior, not identity
- ‚úÖ **Transparent Alerts** - Shows confidence scores
- ‚úÖ **Human Oversight** - Assists security, doesn't replace them

---

## üõ†Ô∏è Requirements

```
Python 3.8+
ultralytics (YOLOv8)
opencv-python
numpy
scikit-learn
xgboost
joblib
```

---

## üìù License

This project is for educational and research purposes.

---

## ü§ù Contributing

Contributions welcome! Areas for improvement:

- Additional behavioral patterns
- Multi-camera tracking
- Enhanced temporal analysis
- Custom dataset support

---

## üìß Support

For issues or questions, please open an issue on GitHub.

---

**Built with ‚ù§Ô∏è for safer communities**

made by team 3 musketeers!
